# Copyediting Review Master Router

**Purpose:** Route copyediting requests to task-specific Haiku subagents at file × task granularity.

---

## Workflow

1. **Bootstrap** → Detect state (fresh or resume)
2. **Interpret request** → Determine which tasks are needed
3. **Diagnostic questions** → Determine paper type and file scope
4. **Task enumeration** → Generate (file, task) pairs
4.5. **Task preview** → Show full task table, get user confirmation
5. **Output setup** → Initialize `notes/` directory
6. **Execute** → Spawn Haiku subagents in parallel
7. **Wrapup** → Deduplicate, summarize
8. **Deliver** → Present results to user

---

## State Management

### State Files

| File | Purpose |
|------|---------|
| `notes/.copyedit_status` | Current phase: `pending` \| `execution` \| `complete` |
| `notes/tasks.json` | Task manifest with status per (file, task) pair |

### tasks.json Schema

```json
{
  "created": "ISO timestamp",
  "paper_type": "A",
  "llm_tagging": true,
  "tasks": [
    {"id": 1, "file": "intro.tex", "task": "grammar", "model": "haiku", "status": "pending"},
    {"id": 2, "file": "intro.tex", "task": "ai_detection", "model": "haiku", "status": "pending"},
    {"id": 3, "file": "intro.tex", "task": "word_choice", "model": "haiku", "status": "pending"},
    {"id": 4, "file": "methods.tex", "task": "grammar", "model": "haiku", "status": "pending"}
  ],
  "paper_tasks": [
    {"id": 100, "task": "structure", "model": "sonnet", "status": "pending"},
    {"id": 101, "task": "flow_extraction", "model": "sonnet", "status": "pending"},
    {"id": 102, "task": "writing_quality", "model": "sonnet", "status": "pending"}
  ]
}
```

**New field:** `llm_tagging` (boolean) - When true, subagents wrap all changes in `\begin{llm}...\end{llm}` blocks for review tracking. Only applies to .tex files.

**Key:** Each (file, task) pair is a separate entry. Subagents read their own prompt files.

### Task Status Values

- `pending` - Not yet started
- `in_progress` - Subagent spawned
- `complete` - Task finished
- `flagged` - Finished with issues

---

## Step 1: Bootstrap

Spawn a lightweight bootstrap subagent:

```
Task: [copyedit:bootstrap] Detect state
Model: haiku

Instructions:
Read prompts/copyedit_bootstrap.md for full instructions.

Return: {phase: "fresh"|"resume", details}
```

**Handle return:**
- `fresh` → Run: `bash {skill_dir}/scripts/new_session.sh {paper_dir}` to archive any prior output, then proceed to Step 2
- `resume` → Skip to Step 6, continue from pending tasks

---

## Step 2: Interpret Request

| Request Pattern | Tasks |
|----------------|-------|
| "Fix grammar" / "Check for errors" | grammar |
| "Check for AI tells" / "Sound less AI" | ai_detection |
| "Improve structure" / "Paper flow" | structure |
| "Extract flow" / "First sentences" | flow_extraction |
| "Word choice" / "Make it punchier" | word_choice |
| "Sentence rhythm" / "Check variation" | sentence_analysis |
| "Strip llm tags" / "Remove llm wrappers" / "Finalize" | strip_llm |
| "Grade writing quality" / "Improve writing" | writing_quality |
| "Comprehensive review" | grammar, ai_detection, word_choice, sentence_analysis |
| "Full review" | All tasks (including writing_quality) |

### Task Ownership (Avoid Duplicates)

| Issue Type | Owner Task |
|-----------|------------|
| Wordiness, weak verbs, nominalization | word_choice |
| Sentence rhythm, monotony, passive patterns | sentence_analysis |
| AI punctuation, transitions, smarmy language | ai_detection |
| Rhetorical patterns: tension, mechanism, number embedding, limitations | ai_detection (quick flag) → writing_quality (definitive) |
| Paragraph quality, mechanism clarity, math precision, intellectual precision | writing_quality |
| Spelling, grammar errors | grammar |

---

## Step 3: Diagnostic Questions

@IMPORT: shared/components/diagnostic_workflow.prompt

---

## Step 4: Task Enumeration

Generate all (file, task) pairs based on request and file scope.

### File-Level Tasks

| Task | Model | Output File |
|------|-------|-------------|
| grammar | haiku | notes/copy_edits.md |
| ai_detection | haiku | notes/ai_detection.md, notes/simplifications.md |
| word_choice | haiku | notes/word_choice_review.md |
| sentence_analysis | haiku | notes/sentence_analysis.md |
| strip_llm | haiku | (no output file - modifies .tex directly) |

### Paper-Level Tasks

| Task | Model | Output File |
|------|-------|-------------|
| structure | sonnet | notes/structure_analysis.md |
| flow_extraction | sonnet | notes/flow_extraction.md |
| writing_quality | sonnet | notes/writing_quality.md |

### Enumeration Logic

```
tasks = []
id = 1

FOR each file in scope:
    FOR each requested file-level task:
        tasks.append({
            id: id++,
            file: file,
            task: task_name,
            model: "haiku",
            status: "pending"
        })

paper_tasks = []
FOR each requested paper-level task:
    paper_tasks.append({
        id: id++,
        task: task_name,
        model: "sonnet",
        status: "pending"
    })
```

---

## Step 4.5: Task Preview

**CRITICAL: Output the full task table BEFORE calling AskUserQuestion.**

After enumerating tasks, display the complete plan for user confirmation.

### Preview Format

Output this table structure:

```
## Task Preview

**Paper Type:** {type} ({description})
**Files:** {file1}, {file2}, ...

### Phase 1: File-Level Tasks (Parallel, Haiku)

| # | File | Task | Output |
|---|------|------|--------|
| 1 | intro.tex | grammar | copy_edits.md |
| 2 | intro.tex | ai_detection | ai_detection.md, simplifications.md |
| 3 | intro.tex | word_choice | word_choice_review.md |
| ... | ... | ... | ... |

**Subtotal:** N file-level tasks

### Phase 2: Paper-Level Tasks (Sequential, Sonnet)

| # | Task | Output |
|---|------|--------|
| 100 | structure | structure_analysis.md |
| 101 | flow_extraction | flow_extraction.md |
| 102 | writing_quality | writing_quality.md |

**Subtotal:** N paper-level tasks

---
**Total:** N tasks
```

### User Confirmation

After displaying the table, use AskUserQuestion:

```json
{
  "header": "Task plan",
  "question": "Review the task list above. What would you like to do?",
  "multiSelect": false,
  "options": [
    {"label": "Proceed (Recommended)", "description": "Start executing all tasks"},
    {"label": "Modify tasks", "description": "Add, remove, or change tasks before running"},
    {"label": "Cancel", "description": "Stop without running any tasks"}
  ]
}
```

### Handling Responses

**"Proceed":** Continue to Step 5

**"Modify tasks":**
1. Ask what to change (remove files, remove task types, add tasks)
2. Update enumeration
3. Output the FULL updated table (not just changes)
4. Ask again until "Proceed" or "Cancel"

**"Cancel":** Stop workflow, output "Review cancelled. No files modified."

### DO NOT:
- Summarize as "14 tasks" without showing the table
- Proceed without explicit user confirmation
- Show only modified tasks after changes (always full table)

---

## Step 5: Output Setup

**Before spawning subagents, initialize output files.**
The `new_session.sh` script already ran in Step 1, so `notes/` is guaranteed clean — all file creates are fresh (no read-then-overwrite needed).

1. Create `notes/` directory if needed
2. Create output files with headers:

| Output File | Header |
|-------------|--------|
| `notes/copy_edits.md` | `# Grammar & Mechanics Corrections` |
| `notes/ai_detection.md` | `# AI Detection Review` |
| `notes/simplifications.md` | `# Suggested Simplifications` |
| `notes/word_choice_review.md` | `# Word Choice Review` |
| `notes/sentence_analysis.md` | `# Sentence Structure Analysis` |
| `notes/writing_quality.md` | `# Writing Quality Assessment` |

3. Write `notes/tasks.json` with enumerated tasks
4. Write `execution` to `notes/.copyedit_status`

---

## Step 6: Execute

### Orchestrator Context Hygiene

**DO NOT read task prompt files** (prompts/tasks/*.prompt) in the orchestrator. Each subagent
reads its own prompt. Reading them here wastes ~50KB of orchestrator context for no purpose.

**DO NOT read old output files** (notes/*.md) unless you need their content for a decision.
The `new_session.sh` script archives prior output. If you must write headers to output files,
use Write directly — do not Read first if the file was just created or cleaned.

### Subagent Spawn Template

Each subagent receives a minimal instruction:

```
Task: [copyedit:{task}] {file}
Model: {model}

Instructions:
Read the task prompt: prompts/tasks/{task}.prompt

File to analyze: {absolute_file_path}
Paper type: {paper_type}
LLM tagging: {llm_tagging}

Output rules:
- APPEND to notes/{output_file}.md
- Start section with: ## [{filename}]
- Follow output format from task prompt
- If LLM tagging is true and file is .tex, wrap changes in \begin{llm}...\end{llm}

Return: {status: complete|flagged, items_found: N}
```

### Context Budget Rules

**CRITICAL:** The orchestrator context window is finite. Subagent results must NOT flow back
into the orchestrator's context. Follow these rules strictly:

1. **Always use `run_in_background: true`** for every Task call
2. **NEVER call TaskOutput** — it returns full agent transcripts (100-300KB each) which will
   blow out context when running 10+ agents
3. **Subagents write results to files** (notes/*.md) — that is the output mechanism
4. **Track completion via task-notifications** — these arrive automatically when agents finish
   and contain only a short summary (~1KB), not the full transcript
5. **Group subagents by file** — spawn ONE agent per file that runs all requested tasks for
   that file, rather than one agent per (file, task) pair. This reduces the number of
   returning task-notifications

### Execution Loop

```
PHASE 1: File-Level Tasks (Parallel)

    pending = tasks WHERE status == "pending"

    IF pending exists:
        Spawn ALL pending in parallel (one Task tool call per entry)
        MUST use run_in_background: true on each Task call
        Each subagent reads its own .prompt file
        DO NOT call TaskOutput — wait for task-notifications instead
        On task-notification arrival: mark status = "complete" or "flagged"
        After all task-notifications received: proceed to Phase 2

PHASE 2: Paper-Level Tasks (After Phase 1)

    IF all file tasks complete:
        FOR each paper_task WHERE status == "pending":
            Order: structure → flow_extraction → writing_quality → methodology
            Spawn subagent with run_in_background: true
            Model: sonnet
            Wait for task-notification, then mark status

PHASE 3: Wrapup

    IF all tasks complete:
        GOTO Step 7
```

### Grammar Multi-Pass

Grammar task uses adversarial iteration internally:
- Pass 1: Initial review
- Pass 2+: Adversarial check until "no errors found"

This is handled by the grammar subagent, not the orchestrator.

---

## Step 7: Wrapup

Spawn wrapup subagent after all tasks complete:

```
Task: [copyedit:wrapup] Complete review
Model: haiku

Instructions:
Read prompts/copyedit_wrapup.md for full instructions.

Context:
- tasks.json: notes/tasks.json
- Output files: notes/*.md

Return: {status, summary, flagged_items}
```

---

## Step 8: Deliver Results

Present wrapup summary to user:
1. Tasks performed and files analyzed
2. Key findings and recommendations
3. Output files created
4. Suggested next steps

---

## Output Format

All output files use checklist format (except copy_edits.md):

```markdown
### - [ ] Lines X-Y: [Brief description]

**Comment:** [Why this is problematic]

**Original:**
```
[Full sentence(s)]
```

**Proposed Revision:**
```
[Complete revision]
```

**Why better:** [Concrete improvements]
```

**Exception:** `copy_edits.md` uses log format: `File:Line → Previous → New`

---

## Error Handling

**Unclear request:** Use AskUserQuestion:

```
Question: "Which aspect of your writing should I focus on?"
Header: "Focus area"
MultiSelect: true
Options:
  - Label: "Grammar and correctness"
    Description: "Fix spelling, punctuation, and mechanical errors"
  - Label: "AI detection and naturalness"
    Description: "Flag AI-generated patterns and suggest alternatives"
  - Label: "Word choice and clarity"
    Description: "Improve precision and concreteness"
  - Label: "Sentence rhythm"
    Description: "Analyze sentence length variation"
```

**Files not found:** Ask user to specify files or subdirectory.

---

## Quality Assurance

**Format Compliance:**
- [ ] Each output file has section headers per source file: `## [filename.tex]`
- [ ] Checklist items have: Comment, Original, Proposed, Why better
- [ ] copy_edits.md uses log format

**Task Completion:**
- [ ] All tasks in tasks.json reached terminal status
- [ ] Wrapup ran deduplication
- [ ] Status set to complete

---

## Invocation Examples

### Start New Review

```
/copyedit review paper.tex
/copyedit ai_detection *.tex
/copyedit full paper/
```

### Resume Interrupted Review

```
/copyedit continue
```

### Reset for New Review

```bash
rm -rf notes/
/copyedit review paper.tex
```
