# Task: AI Detection (Punctuation, Structure & Language)

**Scope:** AI-specific patterns ONLY. This task does NOT cover:
- Wordiness/weak verbs (â†’ `word_choice.prompt`)
- Sentence rhythm/monotony (â†’ `sentence_analysis.prompt`)
- Passive voice issues (â†’ `sentence_analysis.prompt`)

**Model:** Haiku (pattern recognition for both punctuation and language patterns)

**Output:**
- `notes/ai_detection.md` â€” Pattern identification (what was found)
- `notes/simplifications.md` â€” Suggested fixes (stylistic, NOT auto-applied)

**Output Mode:** APPEND â€” do not overwrite existing content

**âš ï¸ These are SUGGESTIONS, not auto-fixes.** Unlike grammar errors, stylistic issues require author judgment.

---

## Section Format

When analyzing a file, append to BOTH files:

**ai_detection.md:**
```markdown
## [filename.tex]
### Part A: Punctuation & Structural Tells
[checklist items...]
### Part B: Language Tells
[checklist items...]
### Part C: Rhetorical & Argument Tells
[checklist items...]
```

**simplifications.md:**
```markdown
## [filename.tex]
[Proposed revisions with explanations â€” organized by priority]
```

---

## Part A: Punctuation & Structural Tells

### Patterns to Flag

**Punctuation:**
- Em-dash overuse: multiple `---` per paragraph (use rarely)
- Excessive parentheticals
- Artificial colons for drama

**Lists & Enumeration:**
- "One is... A second is... A third is..."
- Artificial balance (exactly 3 items when 2 or 4 is natural)

**Transitions:**
- "Moreover," "Additionally," "Furthermore" at paragraph starts
- "More broadly," "Taken together" (signals pivot to generalization)
- "In contrast," used as sentence opener instead of subordinate clause
- "Critically, however" openers
- "Notably," "Importantly" overuse

**Template Structures:**
- "Despite these challenges..."
- "In conclusion / In summary / Overall" (formulaic endings)
- "Challenges and future prospects" section endings
- "Not only... but also..." constructions
- Rule-of-three padding (artificial three-item lists beyond natural enumeration)
- "From X to Y" flourishes
- Paragraph-ending restatements: restating what was just established instead of ending on the evidence
- Long inline parentheticals (>10 words) that should be footnotes to keep the argument streamlined

---

## Part B: Language Tells

### Patterns to Flag

**ðŸš¨ Smarmy Reframing (HIGH PRIORITY â€” very AI-typical):**
- "It's not X, it's Y" constructions
- "The question isn't... it's..."
- "This isn't about... it's about..."
- "The real issue isn't... it's..."
- "What matters isn't... but rather..."

These sound rhetorically clever but are overused by AI. Replace with direct statements.

**Formulaic Openers:**
- "This occurs because..." / "This is because..." as standalone opener (integrate the reason into the prior sentence instead)
- "Put differently..."
- "From a [X] perspective..."

**Meta-Commentary & Collaboration Language:**
- "The paper proceeds in three parts..."
- "[Analysis] yields two main conclusions..."
- "Let's walk through..."
- "Below is a detailed overview..."
- "As we can see..." / "As mentioned above..."
- "It is important to remember..." (moralizing)
- "It is worth noting that..." / "It bears mentioning..."

**Hedging:**
- "Our results suggest that" (when identification is credible)
- "Is consistent with" (weak phrasing)
- Overuse of "arguably," "potentially," "plausibly"
- Stacked hedges: two or more hedges in one sentence ("roughly appears to suggest"); one hedge per claim maximum
- Non-load-bearing hedges: "roughly" when not a true approximation, "appears" when not genuinely uncertain
- "Unlikely to be sufficient," "may not fully capture" â€” reflexive softening that reads as uncertain rather than careful

**Over-Explanation:**
- Explaining Econ 101 to field experts
- Explaining the obvious

**AI Vocabulary (flag when overused: 2+ occurrences or AI-typical context):**
- align, crucial, delve, elaborate, emphasize, enhance
- enduring, foster, garner, highlight, intricate, interplay
- pivotal, showcase, tapestry, underscore, leverage, robust
- nuanced, multifaceted, comprehensive, facilitate

**Padding Phrases:**
- "highlighting," "underscoring" (as sentence fillers)
- "plays a pivotal role," "continues to captivate"
- "serves as a testament to," "stands as a reminder"

**Content Style:**
- Exaggerating meaning, symbolism, or significance
- Abstract platitudes instead of concrete facts/examples
- Flowery or overly formal tone where casual fits
- Didactic lines that moralize

---

## Part C: Rhetorical & Argument Tells (Quick Flag Only)

**Note:** Part C is a quick-flag pass. It identifies rhetorical patterns that *look* LLM-typical. Definitive paragraph-level assessment â€” whether the argument is sound, the mechanism is clear, the math is precise â€” is handled by the `writing_quality` task (Sonnet). Flag patterns here; defer judgment there.

These patterns reflect how LLM prose structures arguments differently from human academic writing. They require reading groups of sentences, not just individual lines.

### Patterns to Flag

**Results-First Openings (no tension):**
- Paragraphs or sections that announce the result and then explain it, instead of building curiosity
- Human pattern: opens with the puzzle, contradiction, or surprising fact; lets explanation follow
- LLM pattern: states the conclusion upfront, then backfills the reasoning

**Missing Causal Mechanism:**
- Numerical comparisons or results stated without explaining *why* the result obtains
- Human pattern: traces the causal chain ("Adding an expensive card incurs fees from both multi-homers and single-homers but increases sales only from single-homers")
- LLM pattern: reports outcomes ("the cap reduces fees by 100 bps and rewards by 132 bps") without unpacking what produces the gap

**Inventory-Style Numbers:**
- Sequences of numbers presented as a list rather than embedded as evidence for claims
- Human pattern: each number answers a "so what?" and serves as evidence mid-sentence
- LLM pattern: fees change by X, rewards change by Y, share changes by Z â€” reads like a table caption, not an argument

**Buried or Omitted Limitations:**
- Known weaknesses softened with hedging language rather than confronted directly
- Human pattern: names limitations explicitly and early, in plain language, then explains what the analysis achieves despite the limitation
- LLM pattern: omits limitations entirely or buries them in hedge-laden qualifications

---

## Output Format (Checklist)

**CRITICAL:** Original and Proposed Revision must show COMPLETE SENTENCES â€” never truncate mid-sentence. This enables batch application via `apply_marked.prompt`.

```markdown
### - [ ] Lines X-Y: [Brief description]

**Comment:** [Why this is AI-typical]

**Original:**
```
[Full sentence(s) containing the issue â€” never fragments]
```

**Proposed Revision:**
```
[Complete revised sentence(s)]
```

**Why better:** [Explanation]
```

---

## Quality Control

- [ ] `ai_detection.md`: Pattern identification appended (not overwritten)
- [ ] `simplifications.md`: Suggested fixes appended (not overwritten)
- [ ] Section header `## [filename.tex]` in both files
- [ ] Part A (punctuation/structure) comprehensive
- [ ] Part B (language) comprehensive â€” especially smarmy reframing and stacked hedges
- [ ] Part C (rhetorical/argument) comprehensive â€” especially missing mechanisms and results-first openings
- [ ] Organized in reading order within each part
- [ ] Each item has Comment/Original/Proposed/Why better
- [ ] Fixes are SUGGESTIONS only â€” not auto-applied to .tex files

### LLM Section Checklist

Before finalizing flags for any LLM-tagged or suspected-LLM section, verify:
- [ ] Does the opening create tension or curiosity, or does it just announce the topic?
- [ ] Is sentence length varied, or is every sentence roughly the same length?
- [ ] Does every number in the text answer a "so what?"
- [ ] Are there more than two hedges in any paragraph?
- [ ] Can any sentence-initial transition be deleted without losing flow?
- [ ] Is the causal mechanism explicit, or does the text only report outcomes?
- [ ] Are minor caveats in footnotes rather than inline?
- [ ] Would a reader familiar with LLM writing recognize this as AI-generated?

**Note:** Items flagged in Part C are quick pattern detections. The `writing_quality` task (Sonnet) provides definitive paragraph-level assessment with actionable rewrites. When both tasks flag the same passage, `writing_quality` takes precedence during wrapup deduplication.
