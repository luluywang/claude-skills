# Type C Paper Overlay: Methodological Innovation

**Paper Type:** Type C - Methodological contribution (new technique, measurement, or identification strategy)

**Examples:** New econometric technique, novel measurement approach, new identification strategy

---

## Key Characteristics

- Main contribution is HOW you answer a question, not just what you find
- Need to explain why existing methods don't work
- Risk of getting too technical too fast
- Must balance methodological detail with economic substance

---

## Task Modifications for Type C Papers

### AI Detection Task

**Additional patterns to flag:**

**Method-first ordering:**
- Leading with technical innovation before economic question
- "We develop a method that..." before explaining what economic question it answers
- Math before intuition

**Excessive generality:**
- "Consider a general shock process, then we specialize..." (reverse it)
- General framework when specific application would be clearer
- Showing off generality at expense of clarity

**Jargon overload:**
- Technical terms without intuition
- Method complexity emphasized over economic substance
- "Our estimator leverages..." when simpler language possible

---

### Structure Task

**Type C priorities:**

**Introduction structure:**
1. Economic question
2. Why existing methods fail/limitation
3. Your methodological innovation (in words, not math)
4. Economic application
5. What you find

**Check for problems:**
- Method introduced before economic question
- No clear statement of existing method limitation
- Math before intuition
- "Illustrative" application (not real empirics)

**Section ordering:**
- Section 2: Method (intuition first, then formalization)
- Section 3: Application to real economic question
- Section 4: Robustness/extensions showing it generalizes
- Avoid: Theory section → Application → "Oh by the way, here's the method"

**Key test:**
- Can reader understand method contribution without equations?
- Is there intuitive explanation before technical details?
- Does method serve economics, or economics serve method?

---

### Methodology Task

**Type C-specific focus:**

**Method explanation priorities:**
1. Economic question comes first
2. Limitation of existing approach (creates space for innovation)
3. Intuition for your method (in plain language)
4. Simple example or special case showing how it works
5. Then formal development
6. Application to real economic question (not toy example)

**Check for:**
- Is economic motivation clear before method?
- Can non-specialist understand the intuition?
- Is there a simple example?
- Does application feel like real empirical work?

**Red flags:**
- Method seems more complex than necessary
- No intuitive explanation
- Math without economic interpretation
- "Illustrative" application
- Method overshadows economic findings

---

### Senior Referee Task (Type C)

**Contribution evaluation priorities for Type C:**

**Method itself IS the contribution - higher bar for genuine innovation:**
- Scrutinize: Is this a new method, or rebranding of existing technique?
- Ask: Does this method solve an important problem that economists couldn't solve before?
- Watch for: Minor technical variations presented as major methodological breakthroughs

**Key contribution questions:**
- What problem can researchers solve with this method that they couldn't solve before?
- Is the problem important enough to justify methodological focus?
- How general is the method - narrow application or broad usefulness?
- Does this enable new substantive research, or just incremental refinements?

**Application quality matters for contribution:**
- Type C needs compelling empirical application, not just toy example
- If application findings are uninteresting, method contribution must be very strong
- Best Type C papers: Method enables surprising findings in application

**Literature positioning challenges:**
- Must position relative to methodological literature (econometrics, statistics, applied micro methods)
- Common problem: Missing related methods in other fields (stats, CS, other social sciences)
- Verify: Have authors correctly claimed novelty vs. existing techniques?

**Specific evaluation questions:**
- Would applied researchers actually use this method?
- Does method work in realistic settings (finite samples, messy data)?
- Is additional complexity justified by improvement over simpler alternatives?
- Does application demonstrate real advantages, or cherry-picked scenario?

**Desk rejection risks for Type C:**
- Method is minor variant of existing technique without meaningful advantage
- Problem being solved is not important or prevalent
- Method only works in very specific, unrealistic scenarios
- No compelling empirical application (just simulation/toy example)
- Contribution is purely technical without economic substance

**What strengthens Type C contribution:**
- Method solves problem that many applied researchers face
- Clear advantages over existing approaches in realistic settings
- Application yields substantive economic insights (method AND findings matter)
- Method is implementable (code available, not overly complex)
- Generalizable across contexts and questions

**Presentation assessment:**
- Is economic motivation clear before technical details?
- Can general economist understand what problem this solves?
- Is intuition provided alongside formal development?

---

### Junior Referee Task (Type C)

**Methods evaluation priorities for Type C:**

**Validation of methodological innovation is critical:**
- Type C contribution rests on method working as claimed
- Scrutinize: Monte Carlo simulations, finite sample properties, sensitivity to violations
- Higher bar: Must show method works in realistic settings, not just theory

**Specific evaluation requirements:**

**Theoretical validation:**
- Are asymptotic properties proven rigorously?
- Are regularity conditions stated explicitly?
- Are assumptions required for method to work realistic?
- What happens when assumptions violated?

**Finite sample performance:**
- Monte Carlo simulations: Comprehensive or cherry-picked?
- Sample sizes realistic for typical applications?
- Data-generating processes representative of real data?
- How does method perform when assumptions violated?

**Comparison to existing methods:**
- Is comparison to relevant alternatives shown?
- Are comparisons fair (same DGP, same sample sizes)?
- When does new method outperform alternatives? When doesn't it?
- Is improvement meaningful or marginal?

**Implementation concerns:**
- Is method computationally feasible?
- Can typical applied researcher implement this?
- Software/code availability?
- Are there practical limitations (data requirements, estimation challenges)?

**Empirical application assessment:**
- Is application genuine empirical work or illustrative toy example?
- Does application show real advantages over existing approaches?
- Are alternative methods applied to same data for comparison?
- Do empirical findings teach us something beyond method validation?

**Required robustness checks for Type C:**
1. **Monte Carlo comprehensiveness**: Multiple DGPs, sample sizes, parameter values
2. **Assumption violations**: How robust is method when assumptions don't hold?
3. **Sensitivity to tuning parameters**: Does method require careful calibration?
4. **Comparison to alternatives**: Head-to-head with existing methods
5. **Empirical robustness**: Application results robust to specification?

**Red flags specific to Type C:**
- Monte Carlos show only scenarios where new method works well
- No comparison to existing methods, or unfair comparisons
- Method requires unrealistic assumptions or data
- Method works theoretically but fails in realistic simulations
- Implementation is so complex that no one will use it
- "Illustrative" application with toy data or well-known example
- Code not provided (method cannot be verified or used)

**Assessment approach:**
- Assume methodological contribution is important if it solves real problem (senior's job)
- Focus: Does method work as claimed? In realistic settings?
- Ask: Would I trust results from a paper using this method?
- Demand: Rigorous validation through theory, simulation, and empirical application

---

## Type C Writing Priorities Summary

### Lead With:
- Economic question
- Why existing methods don't work
- Your approach in plain language

### Spend Time On:
- Intuition before math
- Simple example showing method works
- Economic interpretation of results
- Robustness showing it generalizes

### Minimize:
- Excessive generality
- Math without intuition
- Technical complexity for its own sake
- Treating empirics as afterthought

### Key Risk to Avoid:
- Method overshadowing economic substance
- Getting too technical too fast
- No intuitive explanation
- "Illustrative" rather than real application

---

## Specific Language Patterns for Type C

### Flag these:

**Method-first opening:**
- "We develop a novel estimator that..." (before economic question)
- "Our contribution is methodological..." (state economics first)
- Leading with technical innovation before motivation

**Excessive generality:**
- "Consider a general process α(L)εₜ, then we specialize..."
- "Without loss of generality, assume..."
- Showing most general case when specific case is clearer

**Missing intuition:**
- Equations without plain-language explanation
- "The estimator is defined as..." without intuitive explanation
- Technical jargon without translation

**Weak application:**
- "To illustrate the method, we apply it to..."
- "As an example, consider..."
- "We provide a simple application..."

### Encourage these:

**Economic question first:**
- "Estimating treatment effects when treatment varies continuously presents challenges..."
- State the economic problem before methodological solution
- "A central question in [field] is... Existing approaches fail because..."

**Intuition before formalization:**
- "The key insight is that when agents bunch, the density slope reveals..."
- "Our approach exploits the fact that..."
- "Intuitively, the method works because..."

**Simple example:**
- "To see how this works, consider the case where..."
- "In the simplest case with no heterogeneity..."
- Transparent special case before general version

**Substantial application:**
- "We apply this method to study..." (real question, not illustration)
- Full empirical work, not toy example
- Economic findings emphasized as much as method

---

## Examples from Type C Papers

### Good Type C opening:
> "Estimating treatment effects when treatment varies continuously presents challenges for standard regression discontinuity designs. We develop a method that exploits bunching in the distribution of the running variable to identify local treatment effects. The key insight is that when agents bunch at kink points, the slope of the density reveals the response to treatment incentives."

**Why it works:**
- Economic problem stated first (continuous treatment)
- Existing method limitation (RD doesn't work well)
- Innovation briefly (bunching approach)
- Intuition immediately (slope of density)

---

## Red Flags for Type C Papers

- [ ] Method introduced before economic question
- [ ] No statement of existing method limitation
- [ ] Math before intuition
- [ ] No simple example or special case
- [ ] "Illustrative" application language
- [ ] Method complexity emphasized
- [ ] Economic findings buried in technical details
- [ ] General version shown then specialized (should reverse)
- [ ] Method overshadows economic substance

If these patterns appear, they should be flagged and revised.
