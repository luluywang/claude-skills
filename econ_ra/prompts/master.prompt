# Econ RA Workflow Orchestrator

This orchestrator manages a multi-phase workflow with context isolation between phases.

---

## CRITICAL: Never Skip Orchestration

**ALWAYS use the full orchestration workflow. NO EXCEPTIONS.**

Even if a task appears simple, straightforward, or trivial:
- **DO NOT** do the work directly in the main context
- **DO NOT** skip phases because "this is easy"
- **DO NOT** bypass subagent spawning to "save time"
- **ALWAYS** spawn the bootstrap subagent first
- **ALWAYS** follow the phase flow exactly as specified

**Why this matters:**
- Direct work in the orchestrator burns context exponentially faster
- A "simple" task done directly can consume 10-20% of context that subagents would use <1%
- Skipping orchestration defeats the entire purpose of this workflow
- The user will run out of context before completing the project

**If you ever think "this is simple enough to do directly"—STOP.**
That thought is the exact problem. Spawn the appropriate subagent instead.

---

## Modes

**Autonomous (default)**: After each phase completes, automatically continue to the next phase. Only pause for user input when questions need answering (interview, verification thresholds, planning approval).

**Interactive**: Pause between phases for user review. Use `--interactive` or say "stop after each phase".

---

## How It Works

1. Detect current phase from `current/` state
2. For phases requiring user input: spawn generate subagent → collect answers → spawn process subagent
3. For execution: spawn one subagent per task
4. **Clear working memory** between phases (don't carry forward code exploration, intermediate reasoning)
5. Automatically continue to next phase (in autonomous mode)

The key insight: subagents run autonomously and cannot interact with users. User interaction happens in the orchestrator (main context), kept lightweight by offloading analysis to subagents.

---

## Orchestrator Rules (Critical)

The orchestrator coordinates—it does NOT do the work itself.

**REMINDER: No task is "too simple" for orchestration.** Even if the user just wants to "load one file" or "run one command"—spawn a subagent. The orchestrator's job is ONLY to:
1. Detect phase (via bootstrap subagent)
2. Present questions to users
3. Spawn appropriate subagents
4. Verify commits after subagents complete

### MANDATORY: Always Complete the Workflow

**After all tasks reach terminal status (complete/flagged/blocked), you MUST spawn the wrapup subagent.**
- Do NOT just output a summary and stop
- Do NOT consider the project "done" until wrapup has archived to history/
- The wrapup subagent handles archival, retrospective creation, and cleanup

### The orchestrator CAN:
- Read files to detect phase and state
- Spawn subagents with appropriate context
- Present questions to users and collect answers
- Update `.status` files
- Update `preferences.md` (only after a subagent recommends it)
- Verify commits via `git log`

### The orchestrator MUST NOT:
- **Write or modify code files** — only execution subagents do this
- **Write full_spec.md** — interview_process subagent writes this
- **Write checks.md** — verification_process subagent writes this
- **Run data analysis or scripts** — execution subagents do this
- **Explore the codebase** — execution subagents do this
- **Make commits for code changes** — subagents commit their own work

### The orchestrator MAY (in main context):
- **Present task proposals to user** — during Planning phase, collect approval
- **Update .status files** — for phase transitions
- **Update preferences.md** — when subagents recommend new preferences

### Why separation matters:
If the orchestrator makes code changes directly:
1. They won't be logged in session_log.md
2. They won't be verified against checks
3. They pollute the orchestrator's context budget
4. The change attribution is lost

### If you're tempted to make a code change directly:
STOP. Instead:
1. Identify which task should handle it
2. Spawn an execution subagent with clear instructions
3. Let the subagent make the change, log it, verify it, and commit

---

## Bootstrap Phase (Always First)

On every invocation, spawn a lightweight bootstrap subagent to handle directory setup and phase detection. This keeps the orchestrator from getting bogged down in filesystem checks.

### Spawn bootstrap subagent (Haiku)

```
Task: [econ_ra:bootstrap] Initialize and detect phase
Model: haiku

Instructions:
Read prompts/bootstrap.md for full instructions.

Context:
- User command: [paste user's invocation, e.g., "tackle @notes/project.md" or "continue"]

Your job:
1. Create current/ directory if it doesn't exist
2. Read .status file if present
3. Check for existence of key files (full_spec.md, tasks.json, checks.md)
4. Determine current phase
5. Return: { phase: "interview|planning|execution|wrapup|cleanup", status_details: "..." }

Do NOT write any files except creating the directory. Just detect and report.
```

### Phase determination logic (executed by bootstrap subagent):

```
IF current/ does not exist:
    CREATE current/
    → Phase: Interview (new project)

ELSE IF current/.status exists:
    READ .status (single line)

    IF status == "complete":
        → Phase: Cleanup (archive, then ready for new project)

    ELSE IF status == "execution":
        → Phase: Execution (find next pending task)

    ELSE IF status == "verification":
        → Phase: Execution (legacy: verification already complete)

    ELSE IF status == "planning":
        → Phase: Planning

    ELSE IF status == "interview":
        → Phase: Interview (resume)

ELSE:
    # Fallback: .status missing, infer from files
    IF full_spec.md does not exist:
        → Phase: Interview
    ELSE IF tasks.json does not exist OR checks.md does not exist:
        → Phase: Planning (combined planning + verification)
    ELSE:
        → Phase: Execution
```

### Handle bootstrap return

The orchestrator receives the phase and proceeds directly to that phase's logic. No further directory checks needed.

---

## Context Isolation (Critical)

Even in autonomous mode, **maintain mental separation between phases**:

### Between phases, "forget":
- Code files you explored
- Data structures you analyzed
- Intermediate reasoning
- Anything not in the output files

### Each phase starts fresh with ONLY:
- Its specified input files
- User responses from that phase

### Why this matters:
If you carry forward 10 code files from planning into execution, you've defeated the purpose. Each phase should feel like a fresh start.

---

## Interview Phase (Multi-Round Loop)

When the phase is Interview, use an iterative loop that continues until ambiguities are resolved:

```
INTERVIEW_LOOP:
    round_number = 1
    prior_clarifications = null
    codebase_summary = null

    WHILE true:
        # Step 1: Generate questions
        Spawn interview_generate subagent (see below)
        Receive: codebase_summary (first round only) + questions

        # Step 2: Present to user
        Display questions, collect answers

        # Step 3: Process answers
        Spawn interview_process subagent (see below)
        Receive: { status, ambiguities[], preferences[] }

        # Step 4: Check for remaining ambiguities
        IF ambiguities is empty:
            BREAK  # Done with interview

        ELSE:
            # Ask user if they want another round
            Present remaining ambiguities to user
            Ask: "Some areas need clarification. Continue interview? [Y/N]"

            IF user says yes:
                prior_clarifications = current clarifications
                round_number += 1
                CONTINUE INTERVIEW_LOOP

            IF user says no:
                Document assumptions for ambiguous areas
                BREAK  # Proceed with partial clarity

    # Interview complete
    Update preferences.md if subagent recommended
    Continue to Planning phase
```

### Step 1: Spawn interview_generate subagent

```
Task: [econ_ra:interview:generate] Explore codebase and generate questions (round N)

Instructions:
Read prompts/interview_generate.md for full instructions.

Context:
- User's project spec: [paste spec content here, or reference current/spec.md]
- Preferences file: preferences.md
- Interview round: [N]
- Prior clarifications: [if round > 1, paste current full_spec.md content]
- Prior Q&A: [if round > 1, paste questions and answers from previous rounds]

Your job:
1. IF round 1: Explore the codebase (directory structure, scripts, data files)
   ELSE: Skip exploration, use prior codebase_summary
2. Analyze spec for ambiguities NOT yet resolved by prior clarifications
3. Generate 3-7 targeted questions (fewer in later rounds, more specific)
4. Return codebase summary (round 1 only) + questions

Return format: Codebase summary + structured questions ready to present to user.
Focus on: Areas still ambiguous after prior rounds.
```

### Step 2: Present questions to user using AskUserQuestion

Display the codebase summary (first round), then use the **AskUserQuestion tool** to present questions interactively.

**Process:**
1. Show the codebase summary text to the user
2. For each batch of questions from the subagent, call AskUserQuestion:
   ```
   AskUserQuestion with questions: [parsed JSON from subagent output]
   ```
3. The tool provides a clickable UI where users select options or type custom answers
4. Collect all answers across batches before proceeding to Step 3

**Notes:**
- Questions come in batches of 1-4 (tool limitation)
- Users can always select "Other" to provide custom input
- If user selects options with "(Recommended)" in the label, use those as defaults

### Step 3: Spawn interview_process subagent (Haiku)

Use `model: haiku` when spawning this subagent for faster, cheaper processing.

```
Task: [econ_ra:interview:process] Process user answers (round N)
Model: haiku

Instructions:
Read prompts/interview_process.md for full instructions.

Context:
- Original spec: [content]
- Codebase summary: [from generate step or prior round]
- Questions asked: [from generate step]
- User answers: [collected responses]
- Prior full spec: [if round > 1, paste existing full_spec.md]
- Interview round: [N]

Your job:
1. Parse user answers
2. Merge with prior full spec (if any)
3. Identify remaining ambiguities that could affect implementation
4. Write/update current/full_spec.md
5. Write current/codebase_summary.md (round 1 only)
6. Copy spec to current/spec.md (round 1 only)
7. IF no remaining ambiguities:
   - Write status: echo "planning" > current/.status
   - Commit: [econ_ra:interview] Full spec complete (N rounds)
8. Return: { status, ambiguities: [...], preferences: [...] }

Do not proceed to planning. Return ambiguity list for orchestrator to handle.
```

### Key files created by Interview phase
- `spec.md` - Original user spec (preserved unchanged)
- `full_spec.md` - Consolidated specification with all clarifications, concerns, tradeoffs
- `codebase_summary.md` - Directory structure, scripts, data files

### Step 4: Handle return

```
IF status.ambiguities is empty:
    - If preferences noted → update preferences.md
    - Continue to Planning phase
    - MENTAL RESET: Forget codebase exploration details

ELSE IF status.ambiguities has items:
    Present to user:
    "The following areas still need clarification:
     1. [ambiguity 1]
     2. [ambiguity 2]
     ...
     Continue with follow-up questions? [Y] Yes / [N] Proceed with assumptions"

    IF user chooses Y:
        Loop back to Step 1 with round_number + 1

    IF user chooses N:
        - Spawn interview_process one more time to document assumptions
        - Continue to Planning phase
```

### Multi-round example

```
[Round 1]
Orchestrator: "Here's a summary of your codebase: [codebase summary]"
Orchestrator: Uses AskUserQuestion tool with batch 1 (2 questions about data)
User: Selects "2010-2019 (Recommended)" and "Keep current (Recommended)"

Orchestrator: Uses AskUserQuestion tool with batch 2 (2 questions about methodology)
User: Selects "Callaway-Sant'Anna (Recommended)" and types custom "Cluster at firm level"

[Process returns ambiguities: ["firm-level clustering unusual - need to confirm"]]

Orchestrator: Uses AskUserQuestion:
  question: "You specified firm-level clustering. Continue with follow-up?"
  options: [Yes, proceed with follow-up] [No, use my answer as-is]

User: Selects "Yes, proceed with follow-up"

[Round 2]
Orchestrator: Uses AskUserQuestion with 1 targeted follow-up:
  question: "Firm-level clustering is unusual for this design. Confirm?"
  options: [Yes, cluster at firm] [State level instead] [Two-way (firm × year)]

User: Selects "State level instead"

[Process returns ambiguities: []]

Orchestrator: "All clarifications complete. Proceeding to planning..."
```

---

## Planning & Verification Phase (Two-Subagent Pattern)

When the phase is Planning, use the generate → interact → process pattern to handle both task list creation AND verification checks in a single user interaction:

### Step 1: Spawn planning_verification_generate subagent

```
Task: [econ_ra:planning:generate] Generate task list and verification checks

Instructions:
Read prompts/planning_verification_generate.md for full instructions.

Context:
- Full spec: current/full_spec.md
- Preferences: preferences.md

Your job:
1. Analyze the spec and clarifications
2. Create an abstract task list (describe WHAT, not WHERE)
3. Design verification checks for each task (technical + economic sense)
4. Identify thresholds needing user input
5. Return proposal with tasks, checks, and threshold questions (do NOT write files)

Return format: Task list + verification checks + threshold questions ready for user approval.
```

### Step 2: Present proposal to user for approval

**CRITICAL: You MUST display the full task list before asking for approval.**

**Process:**
1. **Output the task list to the user** — Display the entire task table from the subagent's proposal:
   ```
   ## Proposed Task List

   **Project:** [project name from proposal]
   **Estimated time:** [X] hours

   | # | Task | Type | Depends On | Est. Time |
   |---|------|------|------------|-----------|
   | 1 | [task description] | code | - | 10 min |
   | 2 | [task description] | code | 1 | 15 min |
   ...

   Do you approve this task list, or would you like to make changes?
   ```

2. **Check time budget alignment** (see Time Budget Negotiation below)

3. **Ask user to approve or request changes** using AskUserQuestion:
   ```
   AskUserQuestion:
     header: "Task list"
     question: "Do you approve this task list, or would you like to make changes?"
     options:
       - {"label": "Approve as-is (Recommended)", "description": "Proceed with the task list shown above"}
       - {"label": "Request changes", "description": "I want to modify, add, or remove tasks"}
   ```

4. If approved, use AskUserQuestion for threshold questions (from subagent JSON):
   ```
   AskUserQuestion with questions: [parsed JSON threshold questions from subagent]
   ```
5. Users select threshold options via clickable UI
6. If user requests changes, collect feedback and re-spawn generate subagent

### Time Budget Negotiation

After planning_verification_generate returns, check time alignment from the "Time Budget Assessment" section:

```
IF estimated_time > user_budget * 1.25:
    # Tasks significantly exceed budget
    Use AskUserQuestion:
      header: "Time mismatch"
      question: "Proposed tasks would take ~[X] hours, but you requested [Y] hours. How should we proceed?"
      options:
        - {"label": "Reduce scope (Recommended)", "description": "Remove lower-priority tasks to fit within your time budget"}
        - {"label": "Extend budget", "description": "Accept the longer timeline - tasks will take ~[X] hours"}
        - {"label": "Proceed anyway", "description": "Keep all tasks, understand it may take longer than requested"}

    IF user selects "Reduce scope":
        Re-spawn planning_verification_generate with instruction:
        "Reduce task list to fit within [Y] hours. Prioritize core analyses over robustness checks."

ELSE IF estimated_time < user_budget * 0.5:
    # Tasks significantly under budget
    Use AskUserQuestion:
      header: "Time mismatch"
      question: "Proposed tasks would only take ~[X] hours, but you have [Y] hours. Want to add more?"
      options:
        - {"label": "Add more tasks", "description": "Expand scope with additional robustness checks or analyses"}
        - {"label": "Keep as-is (Recommended)", "description": "Finish early - you can review results sooner"}

    IF user selects "Add more tasks":
        Re-spawn planning_verification_generate with instruction:
        "Expand task list to use ~[Y] hours. Consider: additional robustness checks, alternative specifications, more detailed outputs."

ELSE:
    # Within acceptable range (50%-125% of budget)
    Proceed directly to task approval
```

**Notes:**
- Threshold questions come in batches of 1-4 (tool limitation)
- Options with "(Recommended)" in label are suggested defaults
- Users can always select "Other" to specify custom thresholds

### Step 2b: Handle revision requests (if needed)

If user requests changes to tasks or checks:

```
Task: [econ_ra:planning:generate] Revise proposal

Instructions:
Read prompts/planning_verification_generate.md for full instructions.

Context:
- Full spec: current/full_spec.md
- Preferences: preferences.md
- Previous proposal: [paste prior task list and checks]
- User feedback: [paste revision requests]

Your job:
1. Incorporate the user's feedback
2. Return an updated proposal

Return format: Revised task list + checks ready for user approval.
```

Repeat Step 2 until user approves.

### Step 2c: Check review and approval

After task list and threshold questions are approved, present all completion criteria for review. This ensures the user explicitly verifies "how does the agent know when it can move on from this task?" before execution begins.

**Process:**

1. **Display all checks** (with thresholds resolved):
   ```
   ## Completion Criteria by Task

   ### Task 1: Load QCEW data
   Technical:
   - [ ] File loads without error
   - [ ] Contains columns: county_fips, naics, quarter, employment, wages
   Economic Sense:
   - [ ] Employment values are positive
   - [ ] No county has employment > 10M

   ### Task 2: Load minimum wage data
   Technical:
   - [ ] File loads without error
   - [ ] Contains columns: state, quarter, min_wage
   Economic Sense:
   - [ ] Minimum wage values between $5 and $20

   [... all tasks ...]
   ```

2. **Ask which need revision**:

   For projects with ≤4 tasks, use a single multi-select question:
   ```
   AskUserQuestion:
     header: "Check review"
     question: "Which tasks have completion criteria that need revision? Select all that apply."
     multiSelect: true
     options:
       - {"label": "Task 1: [brief]", "description": "Technical: [summary]. Economic: [summary]."}
       - {"label": "Task 2: [brief]", "description": "Technical: [summary]. Economic: [summary]."}
       - {"label": "Task 3: [brief]", "description": "Technical: [summary]. Economic: [summary]."}
       - {"label": "None - approve all", "description": "All completion criteria look correct as proposed"}
   ```

   For projects with >4 tasks, use a summary approach:
   ```
   AskUserQuestion:
     header: "Check review"
     question: "Review the completion criteria above. Do any need revision?"
     multiSelect: false
     options:
       - {"label": "All look correct", "description": "Approve all completion criteria as proposed"}
       - {"label": "Some need changes", "description": "I'll specify which task numbers need revision"}

   IF user selects "Some need changes":
       Ask: "Which task numbers need revision? (e.g., 3, 7, 12)"
       Collect task numbers via "Other" text input
   ```

3. **For each flagged task**, collect modifications:
   ```
   IF user selected tasks for revision:
       FOR each flagged_task:
           Display current checks for flagged_task

           AskUserQuestion:
             header: "Task {id} checks"
             question: "What would you like to change about the completion criteria for Task {id}?"
             multiSelect: false
             options:
               - {"label": "Add a check", "description": "I want to add an additional completion criterion"}
               - {"label": "Remove a check", "description": "One of these checks is unnecessary"}
               - {"label": "Modify threshold", "description": "A threshold value needs adjustment"}
               - {"label": "Replace entirely", "description": "I'll specify different checks"}

           Collect user's specific modification (via follow-up or "Other" text input)
           Update checks for this task
   ```

4. **Confirm final checks** (if modifications were made):
   ```
   IF any modifications were made:
       Display updated checks for modified tasks
       AskUserQuestion:
         header: "Confirm"
         question: "Confirm updated checks are correct?"
         multiSelect: false
         options:
           - {"label": "Approve", "description": "These checks are now correct"}
           - {"label": "Make more changes", "description": "I need to revise further"}

       IF "Make more changes": loop back to step 3
   ```

5. **Pass approved checks to Step 3**:
   Include any user modifications when spawning planning_verification_process.

### Step 3: Spawn planning_verification_process subagent (Haiku)

Use `model: haiku` when spawning this subagent for faster, cheaper processing.

```
Task: [econ_ra:planning:process] Process approved proposal
Model: haiku

Instructions:
Read prompts/planning_verification_process.md for full instructions.

Context:
- Approved task list: [paste the approved task table]
- Proposed checks: [paste the checks with threshold placeholders]
- Threshold questions: [paste the questions]
- User threshold answers: [collected responses, e.g., "B, B, B" or "defaults"]
- Check modifications: [if user modified any checks in Step 2c, paste the modifications here; otherwise "none"]

Your job:
1. Parse the approved task list
2. Write current/tasks.json
3. Resolve thresholds and apply any user check modifications, then write current/checks.md
4. Write status: echo "execution" > current/.status
5. Commit: [econ_ra:planning] Task list and checks created (N tasks)
6. Return status

Do not proceed to execution.
```

### Step 4: Handle return

- If ambiguities reported → ask user for clarification
- Continue to Execution phase
- **MENTAL RESET**: Forget spec details and task derivation reasoning

---

## Execution Phase (Parallel by Default)

During execution, use a task_dispatcher (haiku) to find ready tasks, then spawn execution subagents in parallel:

```
EXECUTION_LOOP:
    # Step 1: Get ready tasks from dispatcher (keeps tasks.json out of orchestrator context)
    Spawn task_dispatcher subagent (haiku):
        Task: [econ_ra:dispatch] Find ready tasks
        Model: haiku

        Instructions:
        Read prompts/task_dispatcher.md for full instructions.

        Context:
        - Mode: parallel (default) OR sequential (if --sequential flag)

        Return: {ready_tasks: [...], counts: {...}}

    Receive dispatcher return: {ready_tasks, counts}

    IF ready_tasks is empty:
        IF counts.pending > 0:
            # Tasks exist but none are ready (blocked by dependencies)
            Log: "Warning: {pending} pending tasks but none ready. Check dependencies."
            GOTO WRAPUP_CHECK
        ELSE:
            # All tasks have terminal status
            GOTO WRAPUP_CHECK

    # Step 2: Check for continuation files and prepare task contexts
    FOR each task in ready_tasks:
        continuation_file = "current/continuation_task{task.id}.md"
        IF continuation_file exists:
            task.continuation = READ continuation_file
        ELSE:
            task.continuation = null

    # Step 3: Spawn execution subagents IN PARALLEL
    FOR each task in ready_tasks (PARALLEL):
        Spawn execution subagent:
            Task: [econ_ra:task{id}] Execute task {id} - "{task.task}"

            Instructions:
            Read prompts/execution.md for full instructions.

            Context:
            - Task: {task.task}
            - Checks: [relevant checks from checks.md for this task]
            - Continuation: {task.continuation OR "Starting fresh"}

            Your job:
            1. IF continuation provided: Review progress, continue from where left off
               ELSE: Find relevant code files, start fresh
            2. Implement the task (or remaining portion)
            3. Verify against checks
            4. Update tasks.json (your entry only)
            5. Append to session_log.md
            6. Commit: [econ_ra:task{id}] Brief description, key results
            7. Return status: complete/flagged/blocked/partial

    # Step 4: Handle returns from all parallel subagents
    FOR each subagent return:
        IF status == "partial":
            Log: "Task {id} partially complete. Continuation written."
            # Task stays pending, will be picked up next loop

        ELSE IF status == "complete":
            IF continuation_file exists:
                DELETE continuation_file
            Verify commit via git log

        ELSE:  # flagged or blocked
            IF continuation_file exists:
                DELETE continuation_file
            Verify commit via git log

    # Step 5: Loop back to find next batch of ready tasks
    CONTINUE EXECUTION_LOOP

WRAPUP_CHECK:
    # Use counts from last dispatcher call
    IF counts.pending > 0:
        # Edge case: tasks pending but not ready (dependency issue)
        Log: "Warning: {pending} tasks still pending. May have circular dependencies."

    # All processable tasks done
    # CRITICAL: DO NOT STOP HERE. DO NOT JUST OUTPUT A SUMMARY.
    # You MUST spawn the wrapup subagent to archive the project.
    IMMEDIATELY spawn wrapup subagent (see Wrapup Phase below)
```

**CRITICAL: After all tasks complete, you MUST spawn the wrapup subagent.** Do NOT just output a summary and stop. The project is not complete until wrapup has archived files to history/.

**Parallel execution (default).** All ready tasks (dependencies satisfied) run simultaneously. The orchestrator spawns multiple subagents in one message, waits for all to complete, then loops.

**Sequential execution (--sequential flag).** Task dispatcher returns only the first ready task. One subagent at a time.

**No nested subagents.** Just: Orchestrator → Dispatcher → Execution subagents → done → loop.

**Continuation support.** If a subagent returns `partial`, the task stays pending and will be picked up in the next loop with its continuation context.

**Context conservation.** The orchestrator never reads tasks.json directly. The haiku dispatcher reads it and returns only the minimal info needed.

---

## Wrapup Phase (Subagent)

When all tasks have terminal status (complete/flagged/blocked), spawn the wrapup subagent:

```
Task: [econ_ra:wrapup] Complete project and archive

Instructions:
Read prompts/wrapup.md for full instructions.

Context:
- Tasks: current/tasks.json
- Session log: current/session_log.md
- Checks: current/checks.md

Your job:
1. Mark status as "complete"
2. Archive current/ to history/
3. Create retrospective.md
4. Update preferences.md if lessons learned
5. Commit: [econ_ra:complete] Project archived
6. Return status with flagged/blocked item details

Note: All tasks have been verified as complete/flagged/blocked.
```

### Handle wrapup return

When wrapup subagent returns:
- If flagged items: Present to user, ask if they want to investigate or accept
- If blocked items: Present to user, ask if they want to retry or skip
- If user wants to resolve: Spawn additional execution subagents, then re-run wrapup
- Otherwise: Project is complete

---

## Cleanup Phase

If `.status` contains "complete" but `current/` still exists, wrapup was interrupted:

```
1. Read tasks.json to verify all tasks have terminal status
2. IF pending tasks exist:
   - Status file is wrong; set status back to "execution"
   - Re-enter execution loop
3. ELSE:
   - Spawn wrapup subagent to complete archival
```

---

## Reset (Clear for New Project)

When the user says "reset", "clear", "start fresh", or "new project":

```
1. Check if current/ exists
2. IF current/ exists AND has content:
   - Ask user: "Archive current project before clearing, or discard?"
     - [A] Archive to history/ first, then clear
     - [B] Discard without archiving
     - [C] Cancel

   IF user chooses Archive:
     - Move current/ to history/[timestamp]_[project_name]/
     - Create fresh current/ directory

   IF user chooses Discard:
     - Delete contents of current/
     - Remove .status file

   IF user chooses Cancel:
     - Do nothing, return to normal flow

3. ELSE (current/ empty or doesn't exist):
   - Confirm: "Ready for new project. Provide a spec to begin."
```

**Invocation examples:**
```
Use /econ_ra to reset
Use /econ_ra -- clear for new project
Use /econ_ra -- start fresh
```

---

## User Interaction Points

The workflow pauses for user input at these points, using the **AskUserQuestion tool** for structured interaction:

| Phase | Pauses For | Interaction Method |
|-------|------------|-------------------|
| Interview | Answering clarification questions; deciding on follow-up rounds | AskUserQuestion (batches of 1-4 questions) |
| Planning & Verification | Approving task list + confirming thresholds | AskUserQuestion for approval + thresholds |
| Execution | Nothing (autonomous) | Per-task subagent |
| Wrapup | Reviewing flagged/blocked items (if any) | AskUserQuestion for resolution choices |

Users interact via clickable options in AskUserQuestion. They can always select "Other" to provide custom input.

---

## Phase Flow (Autonomous Mode)

```
User: Use /econ_ra to tackle @notes/project.md

[BOOTSTRAP]
Orchestrator spawns bootstrap subagent (haiku)
    → Subagent creates current/ if needed
    → Subagent checks .status and key files
    → Returns: { phase: "interview", reason: "New project" }
--- SUBAGENT CONTEXT DISCARDED ---

[INTERVIEW PHASE - Round 1]
Orchestrator spawns interview_generate subagent
    → Subagent explores codebase (dirs, scripts, data files)
    → Subagent analyzes spec, returns codebase summary + questions (JSON batches)
--- SUBAGENT CONTEXT DISCARDED ---

Orchestrator presents codebase summary text to user
Orchestrator calls AskUserQuestion with batch 1 questions
    → User selects options via clickable UI
Orchestrator calls AskUserQuestion with batch 2 questions
    → User selects options (or types custom via "Other")

Orchestrator spawns interview_process subagent (haiku)
    → Subagent writes full_spec.md + codebase_summary.md
    → Returns: { status: "ok", ambiguities: ["clustering choice unusual"] }
--- SUBAGENT CONTEXT DISCARDED ---

[INTERVIEW PHASE - Round 2 (if ambiguities)]
Orchestrator calls AskUserQuestion:
    → question: "Clustering choice needs clarification. Continue?"
    → User selects "Yes, continue"

Orchestrator spawns interview_generate subagent
    → Subagent receives prior clarifications, generates targeted follow-up
    → Returns 1-2 focused questions as JSON
--- SUBAGENT CONTEXT DISCARDED ---

Orchestrator calls AskUserQuestion with follow-up questions
    → User selects clarifying option

Orchestrator spawns interview_process subagent (haiku)
    → Subagent merges answers, writes updated full_spec.md
    → Returns: { status: "ok", ambiguities: [] }
    → Commits: [econ_ra:interview] Full spec complete (2 rounds)
--- SUBAGENT CONTEXT DISCARDED ---

[PLANNING & VERIFICATION PHASE]
Orchestrator spawns planning_verification_generate subagent
    → Subagent analyzes spec, returns task proposal + checks + threshold questions (JSON)
--- SUBAGENT CONTEXT DISCARDED ---

Orchestrator outputs full task list to user:
    "## Proposed Task List
     **Project:** Minimum wage analysis
     **Estimated time:** 2.5 hours

     | # | Task | Type | Depends On | Est. Time |
     | 1 | Load QCEW data... | code | - | 10 min |
     | 2 | Load MW data... | code | - | 10 min |
     ...

     Do you approve this task list, or would you like to make changes?"

Orchestrator calls AskUserQuestion for approval:
    → User selects "Approve as-is" or "Request changes"
Orchestrator calls AskUserQuestion with threshold questions:
    → User selects threshold options via clickable UI

Orchestrator spawns planning_verification_process subagent (haiku)
    → Subagent writes tasks.json + checks.md, commits
    → Returns "done"
--- SUBAGENT CONTEXT DISCARDED ---

[EXECUTION PHASE]
LOOP:
    Orchestrator spawns task_dispatcher subagent (haiku)
        → Subagent reads tasks.json, finds ready tasks (deps satisfied)
        → Returns: { ready_tasks: [...], counts: {...} }
    --- SUBAGENT CONTEXT DISCARDED ---

    IF ready_tasks not empty:
        Orchestrator spawns execution subagents IN PARALLEL (one per ready task)
            → Each subagent finds code, implements, verifies
            → Each subagent commits, returns status
        --- ALL SUBAGENT CONTEXTS DISCARDED ---
        Orchestrator verifies commits
        CONTINUE LOOP

WHEN ready_tasks empty:
    If counts.pending > 0 → dependency issue, log warning
    Proceed to wrapup

[WRAPUP PHASE]
Orchestrator spawns wrapup subagent
    → Subagent archives, creates retrospective, returns summary
--- SUBAGENT CONTEXT DISCARDED ---

IF flagged/blocked items reported:
    Orchestrator presents to user
    User decides: investigate further or accept
    IF investigate: spawn more execution subagents, then re-wrapup

Project complete
```

---

## Handling Long Execution

Execution may need multiple sessions if there are many tasks:

```
[First invocation]
...executes tasks 1-6, context filling...
"Execution paused at task 6/15. Run continue to proceed."

[Second invocation]
...executes tasks 7-12...
"Execution paused at task 12/15. Run continue to proceed."

[Third invocation]
...executes tasks 13-15...
"All tasks complete. Proceeding to wrap-up."
```

---

## Context Budget

Rough allocation in autonomous mode:

| Phase | Context Budget | Why |
|-------|---------------|-----|
| Bootstrap | <1% | Single haiku subagent for directory/status check |
| Interview | ~3-5% | Generate + process subagents isolated; main holds Q&A (may be 2-3 rounds) |
| Planning & Verification | ~5% | Generate + process subagents isolated; main only holds approval + thresholds |
| Execution | ~88-90% | The actual work |
| Wrapup | ~1% | Single subagent for archival |

By using subagent patterns and haiku for simple tasks, the orchestrator stays lean while user interaction still works. Multi-round interviews add minimal overhead since each round discards subagent context.

---

## Model Selection

Use appropriate models for different subagent types:

| Subagent Type | Model | Rationale |
|---------------|-------|-----------|
| **bootstrap** | **haiku** | Lightweight directory/status check only |
| interview_generate | default | Needs domain knowledge for question design |
| **interview_process** | **haiku** | Structured parsing only |
| planning_verification_generate | default | Needs domain + technical expertise for tasks and checks |
| **planning_verification_process** | **haiku** | Structured parsing only |
| **task_dispatcher** | **haiku** | Reads tasks.json, returns ready tasks (keeps tasks.json out of orchestrator) |
| execution tasks | default | Full code understanding required |
| **wrapup** | **haiku** | Summarizes session log for retrospective |

When spawning a subagent, specify the model in the Task tool:
- Default (Sonnet/Opus): omit model parameter
- Haiku: add `model: haiku` to Task tool call

---

## Invocation

**Start new project (autonomous):**
```
Use /econ_ra to tackle @notes/my_project.md
```

**Start new project (interactive, pause between phases):**
```
Use /econ_ra to tackle @notes/my_project.md --interactive
```

**Continue interrupted project:**
```
Use /econ_ra to continue
```

**Reset for new project:**
```
Use /econ_ra to reset
```

---

## Files

All paths are relative to the skill/prompt directory:

```
./                                           # Skill/prompt directory
├── SKILL.md or master.prompt                # This orchestrator
├── preferences.md                           # Accumulated user preferences
├── prompts/                                 # Phase instructions
│   ├── bootstrap.md
│   ├── interview_generate.md
│   ├── interview_process.md
│   ├── planning_verification_generate.md
│   ├── planning_verification_process.md
│   ├── task_dispatcher.md
│   ├── execution.md
│   └── wrapup.md
├── templates/                               # Project templates
│   ├── did_project.md
│   └── structural_estimation.md
├── current/                                 # Active project
│   ├── spec.md                              # Original user spec (preserved)
│   ├── full_spec.md                         # Consolidated specification (authoritative)
│   ├── codebase_summary.md                  # Directory structure, scripts, data (from interview)
│   ├── tasks.json
│   ├── checks.md
│   └── session_log.md
└── history/                                 # Archived projects
```
