# PDF Parser Master Router

**Purpose:** Convert economics research PDFs into structured markdown with tables, figures, and equations extracted.

> **Why this tool exists:** If you are using this prompt, the PDF is too large to read directly with Claude's native PDF support. This tool splits the PDF into individual pages and extracts text, allowing Claude to process documents that would otherwise exceed context limits. Do NOT attempt to read the original PDF directly—use the extracted cache files instead.

---

## Workflow

1. **Extract PDF content** → Run shell script to split pages and extract text
2. **Segment document** → Identify structure (sections, page ranges)
3. **Process components** → Extract tables, figures, equations as needed
4. **Assemble output** → Combine into final markdown
5. **Quality check** → Validate output completeness

---

## Step 1: Request Routing

| Request Pattern | Action |
|----------------|--------|
| "Process this PDF" / "Parse paper.pdf" / Full extraction | Full workflow below |
| "Extract tables from pages X-Y" | `tasks/extract_tables.md` |
| "Describe figures" / "What figures are in this paper?" | `tasks/describe_figures.md` |
| "Convert equations to LaTeX" | `tasks/convert_equations.md` |
| "Clean up extracted text" | `tasks/clean_text.md` |
| "What's the structure of this paper?" | `tasks/segment.md` |
| "Validate table extraction" | `tasks/validate_tables.md` |
| "Run QA on output" | `tasks/qa_check.md` |

---

## Step 2: PDF Extraction (Shell Scripts)

**For a new PDF, always start here:**

```bash
# Single PDF processing
./scripts/process_paper.sh /path/to/paper.pdf

# Multiple PDFs
./scripts/batch_process.sh /path/to/folder
```

This creates:
- `cache/[PAPER]/text/page_*.txt` - Extracted text per page
- `cache/[PAPER]/layout/page_*.txt` - Layout-preserved text
- `cache/[PAPER]/segment_task.md` - Ready for segmentation

**Cache management:**
```bash
./scripts/cache.sh status              # Show cached papers
./scripts/cache.sh clear               # Clear all cache
./scripts/cache.sh clear "Paper Name"  # Clear specific paper
```

---

## Step 3: Document Segmentation

After PDF extraction, identify document structure:

@IMPORT: tasks/segment.md

**Input:** `cache/[PAPER]/segment_task.md`
**Output:** `cache/[PAPER]/structure.json`

The structure.json contains:
- Title, authors, abstract
- Section names with page ranges
- References start page
- Appendix start page (if present)

---

## Step 4: Component Processing

Based on structure.json, process relevant pages:

### Tables
@IMPORT: tasks/extract_tables.md

**Input:** Layout text from pages with tables
**Output:** `cache/[PAPER]/tables/page_N.json`

### Figures
@IMPORT: tasks/describe_figures.md

**Input:** Text + PDF pages with figures
**Output:** `cache/[PAPER]/figures/page_N.json`

### Equations
@IMPORT: tasks/convert_equations.md

**Input:** Section text containing math
**Output:** `cache/[PAPER]/equations/section_NAME.json`

### Text Cleaning
@IMPORT: tasks/clean_text.md

**Input:** Raw section text
**Output:** `cache/[PAPER]/cleaned/SECTION_NAME.md`

---

## Step 5: Full Orchestration

For complete end-to-end processing of a paper:

@IMPORT: tasks/orchestrate.md

This runs all phases:
1. Segmentation (if needed)
2. Parallel processing of tables, figures, equations, text
3. Table validation
4. Assembly into final markdown
5. QA check

**Output:**
- `output/[PAPER_NAME].md` - Final structured document
- `output/[PAPER_NAME]_qa.json` - Quality report

---

## Step 6: Quality Assurance

@IMPORT: tasks/qa_check.md

Validates:
- All sections present
- Table/figure references resolved
- Footnotes collected
- No missing content

---

## Quick Reference

| Task | Prompt | Input | Output |
|------|--------|-------|--------|
| Structure | `tasks/segment.md` | segment_task.md | structure.json |
| Tables | `tasks/extract_tables.md` | layout/page_N.txt | tables/page_N.json |
| Figures | `tasks/describe_figures.md` | text/page_N.txt | figures/page_N.json |
| Equations | `tasks/convert_equations.md` | text/page_N.txt | equations/section.json |
| Text | `tasks/clean_text.md` | text/page_*.txt | cleaned/SECTION.md |
| Validate | `tasks/validate_tables.md` | tables + context | validation/table_N.json |
| QA | `tasks/qa_check.md` | assembled markdown | *_qa.json |
| Full run | `tasks/orchestrate.md` | segment_task.md | output/*.md |

---

## Example: Process a Paper

```
User: "Process paper.pdf and extract everything"

1. Run extraction:
   ./scripts/process_paper.sh paper.pdf

2. Check cache created:
   ls cache/paper/

3. Load orchestrate.md for full processing:
   @IMPORT: tasks/orchestrate.md

4. Follow orchestration phases to completion

5. Output: output/paper.md + output/paper_qa.json
```

---

## Error Handling

**PDF extraction fails:** Check PDF is not password-protected, try with `--debug` flag

**Structure unclear:** Use segment.md with more context pages

**Tables garbled:** Use layout text instead of plain text, validate with validate_tables.md

**Missing content:** Check QA report, re-extract specific pages

---

## Directory Structure

```
parsepdf/
├── cache/                     ← Runtime cache (not distributed)
├── output/                    ← Generated output (not distributed)
├── dev/                       ← Development/examples/docs
└── prompts/
    ├── master.prompt          ← This file (entry point)
    ├── tasks/                 ← Individual task prompts
    │   ├── segment.md
    │   ├── extract_tables.md
    │   ├── describe_figures.md
    │   ├── convert_equations.md
    │   ├── clean_text.md
    │   ├── validate_tables.md
    │   ├── qa_check.md
    │   └── orchestrate.md
    ├── components/            ← Reusable prompt components
    └── scripts/               ← Shell scripts
        ├── process_paper.sh   ← PDF extraction
        ├── batch_process.sh   ← Batch processing
        └── cache.sh           ← Cache management
```
